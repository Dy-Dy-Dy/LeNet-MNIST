{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 检查是否有可用 GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "训练集大小: 60000\n",
      "测试集大小: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "# transforms.ToTensor() 将 [0,255] 范围的像素值归一化到 [0,1] \n",
    "# transforms.Normalize((0.5,), (0.5,)) 再进一步将其线性变换到 [-1,1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 下载并加载训练集\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',       # 数据集下载或存放的路径\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,       # 一次处理的样本数\n",
    "    shuffle=True         # 训练时打乱数据\n",
    ")\n",
    "\n",
    "# 下载并加载测试集\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1000,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"训练集大小:\", len(train_dataset))\n",
    "print(\"测试集大小:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 输入通道为1 (灰度图)，输出通道为6，卷积核 5x5\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        # 平均池化\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # 卷积层，输入通道为6，输出通道为16，卷积核 5x5\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        # 全连接层，16*4*4 的原因： \n",
    "        # 28x28 -> (conv1后) 24x24 -> (pool后) 12x12 -> (conv2后) 8x8 -> (pool后) 4x4\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)  # 输出为10类\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一次卷积 + Tanh 激活\n",
    "        x = torch.tanh(self.conv1(x))\n",
    "        # 第一次池化\n",
    "        x = self.pool(x)\n",
    "        # 第二次卷积 + Tanh 激活\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        # 第二次池化\n",
    "        x = self.pool(x)\n",
    "        # 展平\n",
    "        x = x.view(x.size(0), -1)  # 等同于 reshape 为 (batch_size, 16*4*4)\n",
    "        # 全连接层 + Tanh 激活\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        # 最后一层，输出没有激活函数，后面会用 CrossEntropyLoss\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = LeNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 1.8784\n",
      "Epoch [1/5], Step [200/938], Loss: 0.6093\n",
      "Epoch [1/5], Step [300/938], Loss: 0.3961\n",
      "Epoch [1/5], Step [400/938], Loss: 0.3267\n",
      "Epoch [1/5], Step [500/938], Loss: 0.2897\n",
      "Epoch [1/5], Step [600/938], Loss: 0.2470\n",
      "Epoch [1/5], Step [700/938], Loss: 0.2073\n",
      "Epoch [1/5], Step [800/938], Loss: 0.1865\n",
      "Epoch [1/5], Step [900/938], Loss: 0.1591\n",
      "Epoch [2/5], Step [100/938], Loss: 0.1309\n",
      "Epoch [2/5], Step [200/938], Loss: 0.1342\n",
      "Epoch [2/5], Step [300/938], Loss: 0.1278\n",
      "Epoch [2/5], Step [400/938], Loss: 0.1091\n",
      "Epoch [2/5], Step [500/938], Loss: 0.1175\n",
      "Epoch [2/5], Step [600/938], Loss: 0.1043\n",
      "Epoch [2/5], Step [700/938], Loss: 0.1016\n",
      "Epoch [2/5], Step [800/938], Loss: 0.0818\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0856\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0777\n",
      "Epoch [3/5], Step [200/938], Loss: 0.0730\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0825\n",
      "Epoch [3/5], Step [400/938], Loss: 0.0730\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0713\n",
      "Epoch [3/5], Step [600/938], Loss: 0.0705\n",
      "Epoch [3/5], Step [700/938], Loss: 0.0717\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0702\n",
      "Epoch [3/5], Step [900/938], Loss: 0.0642\n",
      "Epoch [4/5], Step [100/938], Loss: 0.0583\n",
      "Epoch [4/5], Step [200/938], Loss: 0.0537\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0615\n",
      "Epoch [4/5], Step [400/938], Loss: 0.0586\n",
      "Epoch [4/5], Step [500/938], Loss: 0.0545\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0547\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0595\n",
      "Epoch [4/5], Step [800/938], Loss: 0.0596\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0471\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0492\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0410\n",
      "Epoch [5/5], Step [300/938], Loss: 0.0520\n",
      "Epoch [5/5], Step [400/938], Loss: 0.0499\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0457\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0451\n",
      "Epoch [5/5], Step [700/938], Loss: 0.0421\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0472\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0493\n",
      "训练完成！\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()              # 交叉熵损失\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # 随机梯度下降\n",
    "\n",
    "num_epochs = 5  # 训练轮数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 训练模式（启用 dropout、batchnorm 等）\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], '\n",
    "                  f'Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在测试集上的准确率: 98.48%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # 测试模式\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # 测试阶段不需要计算梯度\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "print(f\"在测试集上的准确率: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存到 lenet_mnist.pth\n"
     ]
    }
   ],
   "source": [
    "save_path = \"lenet_mnist.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"模型已保存到 {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成，进入测试模式\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dy\\AppData\\Local\\Temp\\ipykernel_14772\\1532832330.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(save_path))\n"
     ]
    }
   ],
   "source": [
    "# 创建一个新的模型实例\n",
    "loaded_model = LeNet().to(device)\n",
    "# 加载训练好的参数\n",
    "loaded_model.load_state_dict(torch.load(save_path))\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"模型加载完成，进入测试模式\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型预测该图片的数字是: 7\n"
     ]
    }
   ],
   "source": [
    "def predict_image(image_path, model):\n",
    "    # 打开图片并转换为灰度\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # 定义与训练时相同的变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),            # 缩放到 28x28\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))    # 与训练集同样的归一化\n",
    "    ])\n",
    "    # 预处理\n",
    "    image = transform(image).unsqueeze(0).to(device)  # 增加一个维度 (batch_size=1)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "# 假如你有一张本地图片 my_digit.png\n",
    "test_image_path = \"my_digit.png\"  # 替换为实际图片路径\n",
    "if os.path.exists(test_image_path):\n",
    "    pred_label = predict_image(test_image_path, loaded_model)\n",
    "    print(f\"模型预测该图片的数字是: {pred_label}\")\n",
    "else:\n",
    "    print(f\"未找到文件 {test_image_path}，请确认路径是否正确。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
